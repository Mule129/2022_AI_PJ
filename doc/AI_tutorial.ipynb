{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# openCV\n",
    "opencv는 이미지, 영상 처리를 도와주는 라이브러리로 제스쳐 인식 코드에서는 웹캠에서 이미지 데이터를 읽어들이고, 그 데이터를 수정(flip, cvtColor 함수 등을 사용)하여 numpy 형식으로 가공하는데 사용\n",
    "\n",
    "비슷한 라이브러리로는 PIL 라이브러리가 있음(이미지 생성, 처리, 가공을 도와주는 라이브러리)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install opencv-python #cmd에서 오픈cv 설치\n",
    "#!pip install opencv-python #코랩에서 오픈cv 설치\n",
    "import cv2 # openCV 모듈 임포트"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 컴퓨터 세계에서 표시하는 차원\n",
    "<img src = \"https://drive.google.com/uc?export=download&id=1lfvWiIUweS8OCJsJHoQRZNmz3cYxpVfO\" width = \"80%\" hieght = \"80%\" >\n",
    "\n",
    "### 행렬, 배열\n",
    "<img src = \"https://drive.google.com/uc?export=download&id=169zhna2raC--4N0yKMltLj9zzw-9c8iy\" align=\"right\" width = \"40%\" hieght = \"40%\" >\n",
    "\n",
    "- 행렬(matrix) : 데이터를 수 또는 다항식 등을 직사각형 모양으로 배열한 것 (=2차원으로 묶은 수)\n",
    "- 배열(array) : 같은 타입의 변수들로 이루어진 유한 집합.\n",
    "\n",
    "### NUMPY\n",
    "\n",
    "numpy 모듈은 대규모 행렬, 배열데이터의 연산처리를 쉽게 할 수 있도록 도와주는 모듈로 마크 몸동작 인식 프로젝트에서는 이미지를 배열 데이터로 변경하여 배열의 차원 변경, 배열 데이터 추가/삭제 등에 사용되었다.\n",
    "\n",
    "\n",
    "\n",
    "### 이미지를 숫자 데이터로 변환하기\n",
    "<img src = \"https://drive.google.com/uc?export=download&id=1nUpQB3Lufp3YwD1I8A07AKGVw0LIvG7a\" width = \"70%\" hieght = \"70%\" >\n",
    "\n",
    "화질이 높을수록(픽셀이 많아질수록) 데이터의 크기가 커진다"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 이미지\n",
    "<img src = \"https://drive.google.com/uc?export=download&id=1vs9jyGGeq36IZh1AWJmIkxCxd5WyWSF_\" align=\"right\" width = \"50%\" hieght = \"50%\" >\n",
    "<img src = \"https://drive.google.com/uc?export=download&id=1YRizpQNGQlwxEJDF_byDMPopLYAlM889\" align=\"right\" width = \"50%\" hieght = \"50%\" >\n",
    "우리가 알고있는 이미지를 컴퓨터로 표현하려면 어떻게 해야할까? 기본적으로 알고있는 것은 이미지의 한 픽셀마다 색을 다르게 하여 이미지를 표현하는 것이다. 이때 픽셀에 어떻게 색이 표시될 수 있을까?\n",
    "- 삼원색\n",
    "\n",
    "삼원색이라 하면 빨강, 노랑, 파랑임을 알고있을 것이다. 색을 적당히 배합함에 따라 흰색이 나오기도, 초록색이 나오기도 한다.\n",
    "- 채널\n",
    "\n",
    "컴퓨터에서 색을 표현하기 위해서는 세 장의 종이(색상 채널)가 필요하다. 첫번째 장에는 빨간색의 양을 표시, 두번째 장에는 노란색의 양을 표시, 세번째 장에는 파란색의 양을 표시한다. 이 세 장의 종이에 0~255사이의 값을 넣어 빨간색은 x만큼, 노란색은 y만큼, 파랑색은 z만큼의 값을 넣으면, 다양한 색을 표현할 수 있다. (흰색 ~ 회색 ~ 검정색은 세가지 색의 값을 255, 255, 255 // n, n, n // 0, 0, 0과 같이 같은 수로 지정하면 된다\n",
    "\n",
    "- 이미지를 배열로 표시하는 방법\n",
    "\n",
    "프로그래밍을 할 때는 세개의 색상 채널을 각각 숫자로 표현해야 한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(True, array([[[ 38,  43,  28],\n",
      "        [ 38,  43,  28],\n",
      "        [ 38,  43,  28],\n",
      "        ...,\n",
      "        [173, 177, 152],\n",
      "        [172, 176, 151],\n",
      "        [169, 173, 148]],\n",
      "\n",
      "       [[ 39,  44,  29],\n",
      "        [ 39,  44,  29],\n",
      "        [ 39,  44,  29],\n",
      "        ...,\n",
      "        [172, 176, 151],\n",
      "        [171, 175, 150],\n",
      "        [168, 172, 147]],\n",
      "\n",
      "       [[ 39,  44,  30],\n",
      "        [ 39,  44,  30],\n",
      "        [ 38,  43,  29],\n",
      "        ...,\n",
      "        [171, 175, 150],\n",
      "        [170, 174, 149],\n",
      "        [168, 172, 147]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[ 80,  73,  56],\n",
      "        [ 77,  70,  53],\n",
      "        [ 75,  68,  51],\n",
      "        ...,\n",
      "        [247, 252, 202],\n",
      "        [247, 251, 200],\n",
      "        [246, 250, 199]],\n",
      "\n",
      "       [[ 80,  72,  55],\n",
      "        [ 76,  68,  51],\n",
      "        [ 73,  65,  48],\n",
      "        ...,\n",
      "        [247, 252, 201],\n",
      "        [247, 251, 200],\n",
      "        [246, 250, 199]],\n",
      "\n",
      "       [[ 77,  68,  51],\n",
      "        [ 71,  63,  46],\n",
      "        [ 68,  60,  43],\n",
      "        ...,\n",
      "        [244, 249, 198],\n",
      "        [245, 249, 198],\n",
      "        [244, 248, 197]]], dtype=uint8))\n",
      "[[[ 37  41  29]\n",
      "  [ 38  42  30]\n",
      "  [ 38  42  30]\n",
      "  ...\n",
      "  [171 176 149]\n",
      "  [170 175 148]\n",
      "  [170 175 148]]\n",
      "\n",
      " [[ 39  42  30]\n",
      "  [ 39  42  30]\n",
      "  [ 39  42  30]\n",
      "  ...\n",
      "  [171 176 149]\n",
      "  [170 175 148]\n",
      "  [170 175 148]]\n",
      "\n",
      " [[ 40  43  31]\n",
      "  [ 40  43  31]\n",
      "  [ 39  42  30]\n",
      "  ...\n",
      "  [172 176 151]\n",
      "  [171 175 150]\n",
      "  [170 174 149]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[ 74  72  54]\n",
      "  [ 74  72  54]\n",
      "  [ 74  72  54]\n",
      "  ...\n",
      "  [248 251 202]\n",
      "  [248 251 202]\n",
      "  [248 251 202]]\n",
      "\n",
      " [[ 73  71  53]\n",
      "  [ 73  71  53]\n",
      "  [ 73  71  53]\n",
      "  ...\n",
      "  [249 254 203]\n",
      "  [248 253 202]\n",
      "  [248 253 202]]\n",
      "\n",
      " [[ 70  68  50]\n",
      "  [ 69  67  49]\n",
      "  [ 68  66  48]\n",
      "  ...\n",
      "  [244 249 198]\n",
      "  [242 247 196]\n",
      "  [241 246 195]]]\n",
      "(480, 640, 3)\n"
     ]
    }
   ],
   "source": [
    "cam = cv2.VideoCapture(0) #cv2에 있는 VideoCapture클래스를 인스턴스화 시킴, 인자 값으로는 0 대입(카메라 포트 id)\n",
    "\n",
    "print(cam.read()) #값을 확인해 보면 튜플 형식(a, b)인 것을 알 수 있음. 여기서 a는 bool(카메라가 켜져있는지, 꺼져있는지)형식, b는 읽어들인 이미지의 3차원 값인 것을 확인 가능\n",
    "\n",
    "vital, img = cam.read() # 0번 포트로 연결된 곳에서 이미지 값을 읽어들임, 반환값은 튜플형(a, b)이기 때문에 vital에는 a값, img에는 b값이 들어감\n",
    "\n",
    "print(img) # 이미지 확인해보기\n",
    "print(img.shape) # 이미지 크기 확인해보기(numpy에 있는 함수)\n",
    "\n",
    "cv2.imshow(\"windows name\", img) # 이미지를 창에 띄우는 함수, 첫번째 인자는 창의 이름, 두번째 인자는 창 안에 들어갈 이미지다\n",
    "\n",
    "if cv2.waitKey(10000) > 0 : # 만약 100ms 내에 키보드를 누르면(키보드를 누르면 입력값을 유니코드로 반환해주는 함수인데, 유니코드는 적어도 0보다 크기 때문에 아무 키나 눌러도 종료됨, 만약 특정 키를 눌렀을때 종료되게 만들고 싶으면 유니코드 표 참고하기)\n",
    "    pass\n",
    "\n",
    "cv2.destroyWindow(\"windows name\") # \"windows name\"이란 이름을 가지고 있는 창 닫기"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 미디어파이프(mediapipe)\n",
    "<img src = \"https://drive.google.com/uc?export=download&id=1Ltv0OB2zV5kZa1hg6Jpgt1tY0f3Q2Lf7\" align=\"right\" width = \"40%\" hieght = \"40%\">\n",
    "미디어파이프는 동작 인식, 물체 인식, 손 인식, 얼굴 인식 등을 학습시켜놓은 인공지능 모델이다. 이 인공지능에게 어떤 것을 인식할건지 알려주고, 인식할 이미지를 건내주면 그에 맞는 예측을 실행한다. 동작인식은 얼굴부터 발 끝까지 32개의 좌표를 찍어 예측하는 방식으로, 제스쳐인식에서는 손 인식과 동작 인식 모델을 사용한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install mediapipe #cmd에서 미디어파이프 설치\n",
    "#!pip install mediapipe #코랩에서 미디어파이프 설치\n",
    "\n",
    "import mediapipe as mp #미디어파이프 임포트"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<module 'mediapipe.python.solutions.pose' from 'c:\\\\Users\\\\Mule129\\\\Documents\\\\GitHub\\\\_venv_py_\\\\lib\\\\site-packages\\\\mediapipe\\\\python\\\\solutions\\\\pose.py'>\n"
     ]
    }
   ],
   "source": [
    "# 미디어 파이프 모듈 사용을 편하게 하기 위해 mp.solutions.pose -> pose로 지정\n",
    "# (import OOO as O 처럼 줄여주는것과 같음, import as 안쓴 이유는 경로 지정이 안되어있어서 불러오지 못함)\n",
    "mp_pose = mp.solutions.pose\n",
    "mp_hand = mp.solutions.hands\n",
    "#\n",
    "print(mp_pose) # 출력된 경로를 보면 solutions 폴더 안의 pose.py 파일이 지정된 것을 볼 수 있음\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n"
     ]
    }
   ],
   "source": [
    "pose = mp_pose.Pose(min_detection_confidence=0.5, min_tracking_confidence=0.5) # 클래스 인스턴트화, 최소 탐지/ 최소 트래킹 신뢰값 설정\n",
    "\n",
    "#img.flags.writeable = False # numpy 에서 지원하는 , 배열이 read only 인지 write 가능인지 설정하는것, 변수를 수정하지 못하게 막는 역할이지만 아래 보다시피 같은 변수에 대입해서 의미 없음\n",
    "img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "pose_result = pose.process(img) # 이미지에서 포즈를 예측하기 위해 process 함수로 이미지 입력\n",
    "\n",
    "hand = mp_hand.Hands(max_num_hands = 1, min_detection_confidence=0.5, min_tracking_confidence=0.5) # 클래스 인스턴스화, 최대 탐지 손 개수, 최소 탐지, 최소 트래킹 신뢰도값 설정\n",
    "\n",
    "hand_result = hand.process(img) # 이미지에서 손을 예측하기 위해 process 함수로 이미지 입력\n",
    "\n",
    "print(pose_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "mp_drawing = mp.solutions.drawing_utils\n",
    "mp_drawing_styles = mp.solutions.drawing_styles\n",
    "\n",
    "# 예측한 결과를 이미지 위에 그려넣기, 이때 어떤 동작에 대해 그릴건지(손인지, 포즈인지 등), 점만 넣을건지, 점과 선을 연결시킬건지, 점과 선의 색상을 어떻게 할 것인지 지정할 수 있다.\n",
    "mp_drawing.draw_landmarks(img, pose_result.pose_landmarks, mp_pose.POSE_CONNECTIONS, landmark_drawing_spec = mp_drawing_styles.get_default_pose_landmarks_style())\n",
    "\n",
    "img = cv2.cvtColor(img, cv2.COLOR_RGB2BGR)\n",
    "img.flags.writeable = True\n",
    "\n",
    "cv2.imshow(\"window name 2\", img)\n",
    "\n",
    "if cv2.waitKey(10000) > 0:\n",
    "    pass\n",
    "\n",
    "cv2.destroyWindow(\"window name 2\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 ('_py_venv_3.8': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4 (tags/v3.10.4:9d38120, Mar 23 2022, 23:13:41) [MSC v.1929 64 bit (AMD64)]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "8fdbd1a8a718dcd891737b9f2c716b91ec843bca5ce8a6d2f5ff447f56ec2dd7"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
